#!/usr/bin/env python3
"""
Audio Effect Preset Generation Model Testing Script
í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì˜¤ë””ì˜¤ ì´í™íŠ¸ë¥¼ ì ìš©í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import torch
import torchaudio
import argparse
import numpy as np
from pathlib import Path
import glob
import json
import re
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
try:
    from pipeline import TextToAudioProcessingPipeline
    from dynamic_pipeline_factory import DynamicPipelineFactory
    from encoder.text_encoder import CLAPTextEncoder
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
    print("í˜„ì¬ ë””ë ‰í† ë¦¬ê°€ AudioManipulator ë£¨íŠ¸ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

class AudioEffectTester:
    """í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì´í™íŠ¸ í…ŒìŠ¤í„°"""
    
    def __init__(self, checkpoint_dir="./checkpoints", device=None):
        """
        Args:
            checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (Noneì´ë©´ ìë™ ì„ íƒ)
        """
        self.checkpoint_dir = checkpoint_dir
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.args = None
        
        print(f"ğŸµ Audio Effect Tester ì´ˆê¸°í™”")
        print(f"   - Device: {self.device}")
        print(f"   - Checkpoint dir: {checkpoint_dir}")
    
    def find_latest_checkpoint(self):
        """ê°€ì¥ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°"""
        if not os.path.exists(self.checkpoint_dir):
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.checkpoint_dir}")
        
        # ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì°¾ê¸°
        checkpoint_pattern = os.path.join(self.checkpoint_dir, "checkpoint_epoch_*.pt")
        checkpoint_files = glob.glob(checkpoint_pattern)
        
        if not checkpoint_files:
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_pattern}")
        
        # ì—í¬í¬ ë²ˆí˜¸ë¡œ ì •ë ¬í•´ì„œ ê°€ì¥ ìµœì‹  ê²ƒ ì„ íƒ
        def extract_epoch(filepath):
            try:
                filename = os.path.basename(filepath)
                # checkpoint_epoch_XX.ptì—ì„œ XX ì¶”ì¶œ
                epoch_str = filename.replace('checkpoint_epoch_', '').replace('.pt', '')
                return int(epoch_str)
            except:
                return -1
        
        latest_checkpoint = max(checkpoint_files, key=extract_epoch)
        latest_epoch = extract_epoch(latest_checkpoint)
        
        print(f"ğŸ“ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {os.path.basename(latest_checkpoint)} (Epoch {latest_epoch})")
        return latest_checkpoint
    
    def load_model(self, checkpoint_path=None):
        """ëª¨ë¸ ë¡œë“œ"""
        if checkpoint_path is None:
            checkpoint_path = self.find_latest_checkpoint()
        
        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {checkpoint_path}")
        
        try:
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            self.args = checkpoint['args']
            
            print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì •ë³´:")
            print(f"   - Epoch: {checkpoint['epoch']}")
            print(f"   - Validation Loss: {checkpoint.get('val_loss', 'N/A')}")
            print(f"   - Text Encoder: {self.args.text_encoder_type}")
            print(f"   - Sample Rate: {self.args.sample_rate}")
            
            # ëª¨ë¸ ì¬êµ¬ì„±
            print("ğŸ”„ ëª¨ë¸ ì¬êµ¬ì„± ì¤‘...")
            
            # DynamicPipelineFactoryë¡œ ëª¨ë¸ ìƒì„± (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ì„¤ì •)
            factory = DynamicPipelineFactory()
            
            self.model = factory.create_pipeline(
                encoder_preset=self.args.text_encoder_type,
                use_clap=True,
                backbone_type='residual',
                decoder_type='parallel',
                sample_rate=self.args.sample_rate,
                use_differentiable_audio=True,
                target_params=500000
            )
            
            # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model = self.model.to(self.device)
            
            # ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
            try:
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print("âœ… ëª¨ë¸ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸  ëª¨ë¸ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                # ë¶€ë¶„ì  ë¡œë“œ ì‹œë„
                model_dict = self.model.state_dict()
                pretrained_dict = {k: v for k, v in checkpoint['model_state_dict'].items() 
                                 if k in model_dict and v.size() == model_dict[k].size()}
                model_dict.update(pretrained_dict)
                self.model.load_state_dict(model_dict)
                print(f"âœ… ë¶€ë¶„ì  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({len(pretrained_dict)}/{len(checkpoint['model_state_dict'])} layers)")
            
            # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def load_audio(self, audio_path, target_length=None):
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"ğŸµ ì˜¤ë””ì˜¤ ë¡œë“œ: {audio_path}")
        
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        
        try:
            # torchaudioë¡œ ë¡œë“œ
            waveform, sample_rate = torchaudio.load(audio_path)
            original_length = waveform.shape[1] / sample_rate  # ì›ë³¸ ê¸¸ì´ ê³„ì‚°
            
            # ëª¨ë…¸ë¡œ ë³€í™˜ (ì±„ë„ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜
            if sample_rate != self.args.sample_rate:
                resampler = torchaudio.transforms.Resample(
                    orig_freq=sample_rate, 
                    new_freq=self.args.sample_rate
                )
                waveform = resampler(waveform)
                print(f"ğŸ”„ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜: {sample_rate}Hz â†’ {self.args.sample_rate}Hz")
            
            # ê¸¸ì´ ì¡°ì • (target_lengthê°€ ì§€ì •ëœ ê²½ìš°ì—ë§Œ)
            if target_length:
                target_samples = int(self.args.sample_rate * target_length)
                current_samples = waveform.shape[1]
                
                if current_samples < target_samples:
                    # íŒ¨ë”©
                    padding = target_samples - current_samples
                    waveform = torch.nn.functional.pad(waveform, (0, padding))
                    print(f"ğŸ”„ ì˜¤ë””ì˜¤ íŒ¨ë”©: {current_samples} â†’ {target_samples} samples")
                elif current_samples > target_samples:
                    # ìë¥´ê¸°
                    waveform = waveform[:, :target_samples]
                    print(f"ğŸ”„ ì˜¤ë””ì˜¤ ìë¥´ê¸°: {current_samples} â†’ {target_samples} samples")
            
            print(f"âœ… ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ: {waveform.shape}, {self.args.sample_rate}Hz")
            return waveform.squeeze(0), original_length  # [length] í˜•íƒœë¡œ ë°˜í™˜, ì›ë³¸ ê¸¸ì´ë„ ë°˜í™˜
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def process_audio(self, audio_tensor, text_prompt):
        """ì˜¤ë””ì˜¤ì— í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì´í™íŠ¸ ì ìš©"""
        print(f"ğŸ›ï¸  ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì‹± ì‹œì‘...")
        print(f"   - Text prompt: {text_prompt}")
        print(f"   - Audio shape: {audio_tensor.shape}")
        
        try:
            with torch.no_grad():
                # í…ì„œë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                audio_tensor = audio_tensor.to(self.device).unsqueeze(0)  # [1, length]
                
                # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ëª¨ë¸ì´ List[str]ì„ ê¸°ëŒ€í•¨)
                if isinstance(text_prompt, str):
                    text_prompts = [text_prompt]
                else:
                    text_prompts = text_prompt
                
                # ëª¨ë¸ì— ì…ë ¥ (ì˜¬ë°”ë¥¸ ìˆœì„œ: texts ë¨¼ì €, audio ë‘ ë²ˆì§¸)
                result = self.model(texts=text_prompts, audio=audio_tensor, use_real_audio=True)
                
                # ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° processed_audio í‚¤ ì‚¬ìš©
                if isinstance(result, dict):
                    preset_params = result.get('preset_params', None)
                    if 'processed_audio' in result:
                        processed_audio = result['processed_audio']
                    elif 'audio' in result:
                        processed_audio = result['audio']
                    else:
                        # ë”•ì…”ë„ˆë¦¬ì˜ ì²« ë²ˆì§¸ í…ì„œ ê°’ ì‚¬ìš©
                        processed_audio = next(iter(result.values()))
                else:
                    processed_audio = result
                    preset_params = None
                
                # ê²°ê³¼ê°€ íŠœí”Œì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                if isinstance(processed_audio, tuple):
                    processed_audio = processed_audio[0]
                
                # ë°°ì¹˜ ì°¨ì› ì œê±°
                if processed_audio.dim() > 1:
                    processed_audio = processed_audio.squeeze(0)
                
                # CPUë¡œ ì´ë™
                processed_audio = processed_audio.cpu()
                
                print(f"âœ… í”„ë¡œì„¸ì‹± ì™„ë£Œ: {processed_audio.shape}")
                return processed_audio, preset_params
                
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì‹± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def save_audio(self, audio_tensor, output_path, sample_rate=None):
        """ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥"""
        if sample_rate is None:
            sample_rate = self.args.sample_rate
        
        print(f"ğŸ’¾ ì˜¤ë””ì˜¤ ì €ì¥: {output_path}")
        
        try:
            # ì˜¤ë””ì˜¤ ì •ê·œí™” (í´ë¦¬í•‘ ë°©ì§€)
            if audio_tensor.abs().max() > 1.0:
                audio_tensor = audio_tensor / audio_tensor.abs().max()
                print("ğŸ”„ ì˜¤ë””ì˜¤ ì •ê·œí™” ì ìš©")
            
            # ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜ (ì±„ë„ ì°¨ì› ì¶”ê°€)
            if audio_tensor.dim() == 1:
                audio_tensor = audio_tensor.unsqueeze(0)  # [1, length]
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = os.path.dirname(output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            
            # ì €ì¥
            torchaudio.save(output_path, audio_tensor, sample_rate)
            print(f"âœ… ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def sanitize_filename(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
        filename = re.sub(r'[^\w\s-]', '', text.strip())
        filename = re.sub(r'[-\s]+', '_', filename)
        # ê¸¸ì´ ì œí•œ (50ì)
        if len(filename) > 50:
            filename = filename[:50]
        return filename.lower()
    
    def save_preset_json(self, preset_params, text_prompt, output_dir, base_filename):
        """ìƒì„±ëœ presetì„ JSON í˜•íƒœë¡œ ì €ì¥"""
        if preset_params is None:
            print("âš ï¸  Preset íŒŒë¼ë¯¸í„°ê°€ ì—†ì–´ JSON ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        try:
            # preset_paramsë¥¼ JSON í˜¸í™˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            def convert_to_serializable(obj):
                """ì¬ê·€ì ìœ¼ë¡œ í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
                if isinstance(obj, torch.Tensor):
                    return obj.cpu().detach().numpy().tolist()
                elif isinstance(obj, dict):
                    return {key: convert_to_serializable(value) for key, value in obj.items()}
                elif isinstance(obj, (list, tuple)):
                    return [convert_to_serializable(item) for item in obj]
                elif isinstance(obj, (int, float, str, bool)) or obj is None:
                    return obj
                else:
                    # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                    return str(obj)
            
            if isinstance(preset_params, torch.Tensor):
                # í…ì„œì¸ ê²½ìš° numpyë¡œ ë³€í™˜ í›„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
                preset_array = preset_params.cpu().detach().numpy()
                preset_dict = self._parse_preset_array(preset_array)
            else:
                # ë”•ì…”ë„ˆë¦¬ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì€ ì¬ê·€ì ìœ¼ë¡œ ë³€í™˜
                preset_dict = convert_to_serializable(preset_params)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata = {
                "timestamp": datetime.now().isoformat(),
                "text_prompt": text_prompt,
                "model_info": {
                    "text_encoder": self.args.text_encoder_type,
                    "sample_rate": self.args.sample_rate,
                    "backbone_type": "residual",
                    "decoder_type": "parallel"
                },
                "preset_parameters": preset_dict
            }
            
            # JSON íŒŒì¼ ì €ì¥
            json_path = os.path.join(output_dir, f"{base_filename}_preset.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ’¾ Preset JSON ì €ì¥ ì™„ë£Œ: {json_path}")
            return json_path
            
        except Exception as e:
            print(f"âŒ Preset JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _parse_preset_array(self, preset_array):
        """Preset ë°°ì—´ì„ ì˜ë¯¸ìˆëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±"""
        preset_dict = {}
        
        if len(preset_array.shape) == 1:
            # 1D ë°°ì—´ì¸ ê²½ìš°
            params = preset_array.tolist()
            
            # íŒŒë¼ë¯¸í„° ê°œìˆ˜ì— ë”°ë¼ ë‹¤ë¥´ê²Œ íŒŒì‹±
            if len(params) >= 25:  # ì¶©ë¶„í•œ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ” ê²½ìš°
                idx = 0
                
                # EQ íŒŒë¼ë¯¸í„° (5 ë°´ë“œ * 3 íŒŒë¼ë¯¸í„° = 15ê°œ)
                eq_params = {}
                for band in range(1, 6):
                    if idx + 2 < len(params):
                        eq_params[f"band_{band}"] = {
                            "center_freq": params[idx],
                            "gain_db": params[idx + 1], 
                            "q": params[idx + 2],
                            "filter_type": "bell" if band in [2, 3, 4] else ("high_pass" if band == 1 else "low_pass")
                        }
                        idx += 3
                preset_dict["equalizer"] = eq_params
                
                # Reverb íŒŒë¼ë¯¸í„° (6ê°œ)
                if idx + 5 < len(params):
                    preset_dict["reverb"] = {
                        "room_size": params[idx],
                        "pre_delay": params[idx + 1],
                        "diffusion": params[idx + 2],
                        "damping": params[idx + 3],
                        "wet_gain": params[idx + 4],
                        "dry_gain": params[idx + 5]
                    }
                    idx += 6
                
                # Distortion íŒŒë¼ë¯¸í„° (4ê°œ)
                if idx + 3 < len(params):
                    preset_dict["distortion"] = {
                        "gain": params[idx],
                        "bias": params[idx + 1],
                        "tone": params[idx + 2],
                        "mix": params[idx + 3]
                    }
                    idx += 4
                
                # Pitch íŒŒë¼ë¯¸í„° (3ê°œ)
                if idx + 2 < len(params):
                    preset_dict["pitch"] = {
                        "pitch_shift": params[idx],
                        "formant_shift": params[idx + 1],
                        "mix": params[idx + 2]
                    }
                    idx += 3
                
                # ë‚˜ë¨¸ì§€ íŒŒë¼ë¯¸í„°ë“¤
                for i, param in enumerate(params[idx:], idx):
                    preset_dict[f"extra_param_{i}"] = param
                    
            else:
                # íŒŒë¼ë¯¸í„°ê°€ ì ì€ ê²½ìš° ë‹¨ìˆœíˆ ë²ˆí˜¸ë¡œ ë§¤í•‘
                for i, param in enumerate(params):
                    preset_dict[f"param_{i}"] = param
        else:
            # ë‹¤ì°¨ì› ë°°ì—´ì¸ ê²½ìš°
            preset_dict["raw_parameters"] = preset_array.tolist()
        
        return preset_dict
    
    def test_audio_effect(self, audio_path, text_prompt, output_path=None, audio_length=None):
        """ì˜¤ë””ì˜¤ ì´í™íŠ¸ í…ŒìŠ¤íŠ¸ (ì „ì²´ íŒŒì´í”„ë¼ì¸)"""
        print(f"\n{'='*60}")
        print(f"ğŸ¯ ì˜¤ë””ì˜¤ ì´í™íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"{'='*60}")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ëª… ì„¤ì •
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            sanitized_prompt = self.sanitize_filename(text_prompt)
            output_dir = os.path.join("./output", f"{timestamp}_{sanitized_prompt}")
            os.makedirs(output_dir, exist_ok=True)
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ëª…ë„ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
            audio_filename = f"{sanitized_prompt}.wav"
            audio_output_path = os.path.join(output_dir, audio_filename)
        else:
            audio_output_path = output_path
            output_dir = os.path.dirname(audio_output_path)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            sanitized_prompt = self.sanitize_filename(text_prompt)
        
        try:
            # 1. ì˜¤ë””ì˜¤ ë¡œë“œ (ì›ë³¸ ê¸¸ì´ ìœ ì§€)
            audio_tensor, original_length = self.load_audio(audio_path, target_length=audio_length)
            
            # 2. ì´í™íŠ¸ ì ìš©
            processed_audio, preset_params = self.process_audio(audio_tensor, text_prompt)
            
            # 3. ê²°ê³¼ ì €ì¥
            self.save_audio(processed_audio, audio_output_path)
            
            # 4. Preset JSON ì €ì¥
            base_filename = sanitized_prompt
            json_path = self.save_preset_json(preset_params, text_prompt, output_dir, base_filename)
            
            # 5. ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±
            metadata_path = os.path.join(output_dir, "metadata.txt")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                f.write(f"Audio Effect Generation Report\n")
                f.write(f"=" * 40 + "\n")
                f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"Input Audio: {audio_path}\n")
                f.write(f"Text Prompt: {text_prompt}\n")
                f.write(f"Original Duration: {original_length:.2f}s\n")
                f.write(f"Sample Rate: {self.args.sample_rate}Hz\n")
                f.write(f"Model: {self.args.text_encoder_type}\n\n")
                f.write(f"Output Files:\n")
                f.write(f"- Audio: {os.path.basename(audio_output_path)}\n")
                if json_path:
                    f.write(f"- Preset: {os.path.basename(json_path)}\n")
                f.write(f"- Metadata: {os.path.basename(metadata_path)}\n")
            
            # 6. ê²°ê³¼ ìš”ì•½
            print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print(f"   - Input: {audio_path}")
            print(f"   - Prompt: {text_prompt}")
            print(f"   - Output Dir: {output_dir}")
            print(f"   - Audio: {os.path.basename(audio_output_path)}")
            if json_path:
                print(f"   - Preset: {os.path.basename(json_path)}")
            print(f"   - Duration: {original_length:.2f}s (original)")
            
            return audio_output_path
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            raise

def main():
    parser = argparse.ArgumentParser(description='Audio Effect Model Tester')
    
    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints',
                       help='ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--checkpoint_path', type=str, default=None,
                       help='íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìµœì‹  ì‚¬ìš©)')
    
    # ì…ë ¥ ê´€ë ¨
    parser.add_argument('--input_audio', type=str, required=True,
                       help='ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--text_prompt', type=str, required=True,
                       help='í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ì ìš©í•  ì´í™íŠ¸ ì„¤ëª…)')
    parser.add_argument('--output_path', type=str, default=None,
                       help='ì¶œë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±)')
    
    # ì˜¤ë””ì˜¤ ê´€ë ¨
    parser.add_argument('--audio_length', type=float, default=None,
                       help='ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ, ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ê¸¸ì´ ì‚¬ìš©)')
    
    # ì‹œìŠ¤í…œ ê´€ë ¨
    parser.add_argument('--device', type=str, default=None,
                       choices=['cpu', 'cuda', 'auto'],
                       help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (autoëŠ” ìë™ ì„ íƒ)')
    
    args = parser.parse_args()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device == 'auto' or args.device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    print("ğŸµ Audio Effect Model Tester")
    print("=" * 50)
    print(f"ğŸ“ Input audio: {args.input_audio}")
    print(f"ğŸ“ Text prompt: {args.text_prompt}")
    print(f"ğŸ’» Device: {device}")
    if args.audio_length:
        print(f"â±ï¸  Audio length: {args.audio_length}s")
    else:
        print(f"â±ï¸  Audio length: original duration")
    
    try:
        # í…ŒìŠ¤í„° ì´ˆê¸°í™”
        tester = AudioEffectTester(
            checkpoint_dir=args.checkpoint_dir,
            device=device
        )
        
        # ëª¨ë¸ ë¡œë“œ
        tester.load_model(args.checkpoint_path)
        
        # ì˜¤ë””ì˜¤ ì´í™íŠ¸ í…ŒìŠ¤íŠ¸
        output_path = tester.test_audio_effect(
            audio_path=args.input_audio,
            text_prompt=args.text_prompt,
            output_path=args.output_path,
            audio_length=args.audio_length
        )
        
        print(f"\nğŸ‰ ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ê²°ê³¼ íŒŒì¼: {output_path}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()