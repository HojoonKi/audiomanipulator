#!/usr/bin/env python3
"""
Dynamic Pipeline Factory for Text-to-Audio Processing

Allows easy experimentation with different text encoders and configurations.
"""

import torch
from typing import Dict, Any, Optional
from pipeline import TextToAudioProcessingPipeline


class DynamicPipelineFactory:
    """
    íŒ©í† ë¦¬ í´ë˜ìŠ¤ë¡œ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ì‰½ê²Œ ì‹¤í—˜í•  ìˆ˜ ìˆë„ë¡ ì§€ì›
    """
    
    # ì‚¬ì „ ì •ì˜ëœ ì¸ì½”ë” ì„¤ì •
    ENCODER_PRESETS = {
        'sentence-transformer-mini': {
            'type': 'sentence-transformer',
            'config': {'model_name': 'all-MiniLM-L6-v2'},
            'description': 'ë¹ ë¥´ê³  ê°€ë²¼ìš´ ë²”ìš© ì¸ì½”ë” (384D)'
        },
        'sentence-transformer-large': {
            'type': 'sentence-transformer', 
            'config': {'model_name': 'all-mpnet-base-v2'},
            'description': 'ê³ í’ˆì§ˆ ë²”ìš© ì¸ì½”ë” (768D)'
        },
        'e5-large': {
            'type': 'e5-large',
            'config': {'model_name': 'intfloat/e5-large-v2'},
            'description': 'ìµœê³  ì„±ëŠ¥ ì˜¤í”ˆì†ŒìŠ¤ ì¸ì½”ë” (1024D)'
        },
        'clap': {
            'type': 'clap',
            'config': {'model_name': '630k-audioset-best'},
            'description': 'ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ íŠ¹í™” ì¸ì½”ë” (512D)'
        }
    }
    
    @classmethod
    def create_pipeline(cls, 
                       encoder_preset: str = 'sentence-transformer-large',
                       custom_encoder_config: Optional[Dict] = None,
                       backbone_type: str = 'simple',
                       backbone_config: Optional[Dict] = None,
                       use_clap: bool = True,
                       **pipeline_kwargs) -> TextToAudioProcessingPipeline:
        """
        ë™ì ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„± - ë°±ë³¸ë„ ë™ì ìœ¼ë¡œ ì§€ì›
        
        Args:
            encoder_preset: ì‚¬ì „ ì •ì˜ëœ ì¸ì½”ë” ì„¤ì • ì´ë¦„
            custom_encoder_config: ì»¤ìŠ¤í…€ ì¸ì½”ë” ì„¤ì • (preset ì˜¤ë²„ë¼ì´ë“œ)
            backbone_type: ë°±ë³¸ íƒ€ì… ('simple', 'dynamic', 'transformer', etc.)
            backbone_config: ë°±ë³¸ ëª¨ë¸ ì„¤ì •
            use_clap: CLAP ì¸ì½”ë” ì‚¬ìš© ì—¬ë¶€
            **pipeline_kwargs: ì¶”ê°€ íŒŒì´í”„ë¼ì¸ ì„¤ì •
            
        Returns:
            TextToAudioProcessingPipeline ì¸ìŠ¤í„´ìŠ¤
        """
        
        # ì¸ì½”ë” ì„¤ì • ê²°ì •
        if custom_encoder_config:
            encoder_type = custom_encoder_config['type']
            encoder_config = custom_encoder_config.get('config', {})
            print(f"ğŸ¯ Using custom encoder: {encoder_type}")
        elif encoder_preset in cls.ENCODER_PRESETS:
            preset = cls.ENCODER_PRESETS[encoder_preset]
            encoder_type = preset['type']
            encoder_config = preset['config']
            print(f"ğŸ¯ Using preset '{encoder_preset}': {preset['description']}")
        else:
            raise ValueError(f"Unknown encoder preset: {encoder_preset}. "
                           f"Available: {list(cls.ENCODER_PRESETS.keys())}")
        
        # ë°±ë³¸ ì„¤ì • ì¤€ë¹„ - ë™ì  ì°¨ì› ì§€ì›
        if backbone_config is None:
            backbone_config = {}
        
        # í…ìŠ¤íŠ¸ ì¸ì½”ë” ì°¨ì› ìë™ ì„¤ì •
        text_dim_map = {
            'sentence-transformer-mini': 384,
            'sentence-transformer-large': 768,
            'e5-large': 1024,
            'clap': 512
        }
        
        # ë°±ë³¸ì— ë™ì  ì°¨ì› ì •ë³´ ì „ë‹¬
        if encoder_preset in text_dim_map:
            backbone_config['text_dim'] = text_dim_map[encoder_preset]
        
        if use_clap:
            backbone_config['clap_dim'] = 512
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        print(f"ğŸ—ï¸ Building dynamic pipeline...")
        print(f"   ğŸ“ Text encoder: {encoder_type}")
        print(f"   ğŸ—ï¸ Backbone: {backbone_type}")
        print(f"   ğŸµ CLAP enabled: {use_clap}")
        
        pipeline = TextToAudioProcessingPipeline(
            text_encoder_type=encoder_type,
            text_encoder_config=encoder_config,
            use_clap=use_clap,
            backbone_type=backbone_type,
            backbone_config=backbone_config,
            **pipeline_kwargs
        )
        
        return pipeline
    
    @classmethod
    def list_presets(cls):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ì½”ë” í”„ë¦¬ì…‹ ëª©ë¡ ì¶œë ¥"""
        print("ğŸ›ï¸ Available Encoder Presets:")
        print("=" * 60)
        
        for name, preset in cls.ENCODER_PRESETS.items():
            print(f"ğŸ“Œ {name}")
            print(f"   Type: {preset['type']}")
            print(f"   Description: {preset['description']}")
            print(f"   Config: {preset['config']}")
            print()
    
    @classmethod
    def benchmark_encoders(cls, test_texts: list = None, device: str = 'cuda'):
        """ë‹¤ì–‘í•œ ì¸ì½”ë”ì˜ ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí¬"""
        if test_texts is None:
            test_texts = [
                "add heavy distortion and reverb",
                "make it sound warmer with chorus", 
                "apply vintage analog compression",
                "create spacious ambient echo"
            ]
        
        print("ğŸ”¬ Encoder Performance Benchmark")
        print("=" * 60)
        
        results = {}
        
        for preset_name in cls.ENCODER_PRESETS.keys():
            try:
                print(f"\nğŸ§ª Testing {preset_name}...")
                
                # íŒŒì´í”„ë¼ì¸ ìƒì„±
                pipeline = cls.create_pipeline(
                    encoder_preset=preset_name,
                    use_clap=False  # ìˆœìˆ˜ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë§Œ í…ŒìŠ¤íŠ¸
                )
                pipeline = pipeline.to(device)
                
                # ì„±ëŠ¥ ì¸¡ì •
                import time
                
                # Warm up
                for _ in range(3):
                    _ = pipeline.encode_text(test_texts)
                
                # ì‹¤ì œ ì¸¡ì •
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                start_time = time.time()
                
                for _ in range(10):  # 10íšŒ í‰ê· 
                    embeddings = pipeline.encode_text(test_texts)
                
                torch.cuda.synchronize() if torch.cuda.is_available() else None
                end_time = time.time()
                
                avg_time = (end_time - start_time) / 10 * 1000  # ms
                per_item_time = avg_time / len(test_texts)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                if torch.cuda.is_available():
                    memory_mb = torch.cuda.memory_allocated() / 1024**2
                else:
                    memory_mb = 0
                
                results[preset_name] = {
                    'avg_time_ms': avg_time,
                    'per_item_ms': per_item_time,
                    'memory_mb': memory_mb,
                    'embedding_dim': embeddings[0].shape[-1] if isinstance(embeddings, tuple) else embeddings.shape[-1],
                    'success': True
                }
                
                print(f"   âœ… Success - {avg_time:.2f}ms total, {per_item_time:.2f}ms/item")
                print(f"      Memory: {memory_mb:.1f}MB, Dim: {results[preset_name]['embedding_dim']}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del pipeline
                torch.cuda.empty_cache() if torch.cuda.is_available() else None
                
            except Exception as e:
                print(f"   âŒ Failed: {e}")
                results[preset_name] = {'success': False, 'error': str(e)}
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š Benchmark Summary:")
        print("-" * 60)
        print(f"{'Preset':<25} {'Time(ms)':<10} {'Per Item':<10} {'Memory(MB)':<12} {'Dim':<6}")
        print("-" * 60)
        
        for name, result in results.items():
            if result['success']:
                print(f"{name:<25} {result['avg_time_ms']:<10.2f} "
                      f"{result['per_item_ms']:<10.2f} {result['memory_mb']:<12.1f} "
                      f"{result['embedding_dim']:<6}")
            else:
                print(f"{name:<25} {'FAILED':<10} {'N/A':<10} {'N/A':<12} {'N/A':<6}")
        
        return results
    
    @classmethod 
    def quick_test(cls, encoder_preset: str = 'sentence-transformer-large',
                   backbone_type: str = 'simple',
                   test_text: str = "add heavy reverb and distortion"):
        """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜"""
        print(f"ğŸš€ Quick test with {encoder_preset} + {backbone_type} backbone")
        
        pipeline = cls.create_pipeline(
            encoder_preset=encoder_preset,
            backbone_type=backbone_type
        )
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        pipeline = pipeline.to(device)
        
        # í…ìŠ¤íŠ¸ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
        embeddings = pipeline.encode_text([test_text])
        
        print(f"âœ… Success!")
        print(f"   Input: '{test_text}'")
        if isinstance(embeddings, tuple):
            text_emb, clap_emb = embeddings
            print(f"   Text embedding: {text_emb.shape}")
            if clap_emb is not None:
                print(f"   CLAP embedding: {clap_emb.shape}")
        else:
            print(f"   Embedding shape: {embeddings.shape}")
        
        return pipeline


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    factory = DynamicPipelineFactory()
    
    # í”„ë¦¬ì…‹ ëª©ë¡ ì¶œë ¥
    factory.list_presets()
    
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    print("\n" + "="*60)
    pipeline = factory.quick_test('sentence-transformer-large', 'dynamic')  # ë™ì  ë°±ë³¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    
    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì˜µì…˜)
    if input("\në²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
        factory.benchmark_encoders()
